{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import functools\n",
    "import time\n",
    "import os\n",
    "import neat\n",
    "import warnings\n",
    "import graphviz\n",
    "import visualize\n",
    "import random\n",
    "import glob\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "WALL      = \"x\"\n",
    "FREE_SPACE= \".\"\n",
    "SAFE_ZONE = \"H\"\n",
    "HIDER     = \"h\" \n",
    "SEEKER    = \"s\"\n",
    "\n",
    "CHAR_MAPPING = {\n",
    "    WALL      : -1,\n",
    "    FREE_SPACE:  0,\n",
    "    SAFE_ZONE :  1,\n",
    "    HIDER     :  2, \n",
    "    SEEKER    :  3\n",
    "}\n",
    "\n",
    "COLOR_MAPPING = [\"black\", \"white\", \"blue\", \"green\", \"red\"]\n",
    "\n",
    "MAP_SIMPLE_NAME = \"map.txt\"\n",
    "\n",
    "ACTIONS = np.array([[-1,0], [1, 0], [0,-1], [0, 1]])\n",
    "VISION = 1\n",
    "SCENT = 5\n",
    "\n",
    "STATE_SEEK = 0\n",
    "\n",
    "REWARD =100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map:\n",
    "        \n",
    "    def __init__(self,mapname, char_mapping):\n",
    "        #read map\n",
    "        with open(mapname, 'r') as map_file:\n",
    "            lines = map_file.readlines()\n",
    "            # width = int(lines[0])\n",
    "            # height = int(lines[1])\n",
    "            map_numbers = [[char_mapping[chr] for chr in row[:-1]] for row in lines[2:]]\n",
    "        self.char_mapping =char_mapping\n",
    "        self.map = np.array(map_numbers, dtype = np.int32)\n",
    "        self.start_hider_pos = np.asarray(np.where(self.map == char_mapping[HIDER])).reshape(2)\n",
    "        self.start_seeker_pos = np.asarray(np.where(self.map == char_mapping[SEEKER])).reshape(2)\n",
    "        \n",
    "        #action array for indexin\n",
    "        self.action_indexer = tuple(ACTIONS.T.tolist())\n",
    "        \n",
    "        #initialize map and backup map\n",
    "        self.map_layout = np.array(map_numbers, dtype = np.int32)\n",
    "        self.map_layout[self.start_hider_pos[0] ,self.start_hider_pos[1] ] = char_mapping[FREE_SPACE]\n",
    "        self.map_layout[self.start_seeker_pos[0],self.start_seeker_pos[1]] = char_mapping[FREE_SPACE]\n",
    "        \n",
    "        #initialize rewards\n",
    "        self.hider_reward = np.zeros_like(self.map_layout)-1\n",
    "        queue = np.where(self.map_layout==char_mapping[SAFE_ZONE])\n",
    "        self.hider_reward[queue]=0\n",
    "        queue = [(x,y)for x,y in zip(*queue)]\n",
    "        while len(queue)>0:\n",
    "            new_queue=[]\n",
    "            for x,y in queue:\n",
    "                for a_x,a_y in ACTIONS:\n",
    "                    if (self.get_map_layout_pos([x+a_x,y+a_y])!=char_mapping[WALL] and\n",
    "                        self.hider_reward[x+a_x,y+a_y]<0):\n",
    "                            self.hider_reward[x+a_x,y+a_y]=self.hider_reward[x,y]+1\n",
    "                            new_queue.append((x+a_x,y+a_y))\n",
    "            queue=new_queue\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.hider_pos  =self.start_hider_pos\n",
    "        self.seeker_pos =self.start_seeker_pos\n",
    "        self.map = np.copy(self.map_layout)\n",
    "        self.set_map_pos(self.hider_pos,  self.char_mapping[HIDER] )\n",
    "        self.set_map_pos(self.seeker_pos, self.char_mapping[SEEKER])\n",
    "\n",
    "        self.hider_reward_penalty = np.zeros_like(self.hider_reward)\n",
    "        self.scent = np.zeros_like(self.map)\n",
    "\n",
    "    def update(self):\n",
    "        pos =self.hider_pos\n",
    "        self.hider_reward_penalty[pos[0], pos[1]]+=1\n",
    "        self.scent[pos[0],pos[1]]=SCENT\n",
    "        self.scent-=1\n",
    "        self.scent = np.clip(self.scent, 0, SCENT)\n",
    "    \n",
    "    def get_map_layout_pos(self,pos):\n",
    "        return self.map_layout[pos[0], pos[1]]\n",
    "    \n",
    "    def set_map_pos(self,pos, value):\n",
    "        self.map[pos[0], pos[1]] = value\n",
    "    \n",
    "    def get_agent_pos(self, agent):\n",
    "        return self.hider_pos if agent ==HIDER else self.seeker_pos\n",
    "    \n",
    "    def set_agent_pos(self, agent, pos):\n",
    "        if agent ==HIDER:\n",
    "            self.hider_pos  =pos\n",
    "        else:\n",
    "            self.seeker_pos =pos\n",
    "    \n",
    "    def get_action_indicies(self, pos):\n",
    "        return (\n",
    "            self.action_indexer[0]+pos[0],\n",
    "            self.action_indexer[1]+pos[1],\n",
    "        )\n",
    "    \n",
    "    def get_percepts(self, agent, vision = 1):\n",
    "        pos =self.get_agent_pos(agent)\n",
    "        if agent==HIDER:\n",
    "            return (self.map[self.get_action_indicies(pos)],[])\n",
    "        else:\n",
    "            percepts = self.map[\n",
    "                pos[0] - vision : pos[0] + vision + 1,\n",
    "                pos[1] - vision : pos[1] + vision + 1\n",
    "            ]\n",
    "            scent= np.append(self.scent[self.get_action_indicies(pos)],self.map[pos[0], pos[1]])\n",
    "            return (percepts,scent) \n",
    "\n",
    "    def is_free(self, pos, agent):\n",
    "        map_pos =self.get_map_layout_pos(pos)\n",
    "        if (agent == HIDER):\n",
    "            return (\n",
    "                map_pos in [self.char_mapping[FREE_SPACE], self.char_mapping[SAFE_ZONE]] and\n",
    "                not np.all(pos == self.seeker_pos)\n",
    "            )\n",
    "        else:\n",
    "            return map_pos in [self.char_mapping[FREE_SPACE]]\n",
    "            \n",
    "    def move_agent(self, agent, new_pos):\n",
    "        pos = self.get_agent_pos(agent)\n",
    "        self.set_map_pos(pos,self.get_map_layout_pos(pos))\n",
    "        self.set_map_pos(new_pos,self.char_mapping[agent])\n",
    "        self.set_agent_pos( agent, new_pos)\n",
    "\n",
    "    def do_action(self, agent, action):\n",
    "        pos = self.get_agent_pos(agent)\n",
    "        new_pos = pos + ACTIONS[action]\n",
    "        if self.is_free(new_pos, agent):\n",
    "            self.move_agent(agent, new_pos)\n",
    "    \n",
    "    def is_end(self):\n",
    "        return np.all(self.hider_pos == self.seeker_pos)\n",
    "\n",
    "    def get_reward(self,pos):\n",
    "         return self.hider_reward[pos[0], pos[1]] - self.hider_reward_penalty[pos[0], pos[1]]\n",
    "\n",
    "        \n",
    "MAP = Map(MAP_SIMPLE_NAME,CHAR_MAPPING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map_jupiter_notebook(map:Map,gen):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure()\n",
    "    plt.title(f\"Generation {gen}\")\n",
    "    plt.imshow(map.map, cmap = matplotlib.colors.ListedColormap(COLOR_MAPPING))\n",
    "    plt.show()\n",
    "    \n",
    "class Map_plot:\n",
    "    def __init__(self, map:Map):\n",
    "        plt.ion()\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.img = self.ax.imshow(map.map , cmap = matplotlib.colors.ListedColormap(COLOR_MAPPING))\n",
    "        \n",
    "    def plot_map(self,map:Map, gen):\n",
    "        self.ax.set_title(f\"Generation {gen}\")\n",
    "        self.img.set_array(map.map)\n",
    "        plt.draw()\n",
    "        self.img.canvas.flush_events()\n",
    "\n",
    "class Map_log:\n",
    "    def __init__(self, log_name):\n",
    "        self.dir = os.path.join(\"logs\",log_name)\n",
    "\n",
    "        self.logs = []\n",
    "        files = glob.glob(os.path.join(self.dir,\"*.npy\"), recursive=True)\n",
    "        for f in files:\n",
    "            try:\n",
    "                os.remove(f)\n",
    "            except OSError as e:\n",
    "                print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "        \n",
    "    def log_map(self,map:Map,gen):\n",
    "\n",
    "        self.logs.append([map.hider_pos,map.seeker_pos])\n",
    "        \n",
    "    def save_and_reset(self, name):\n",
    "        if not os.path.exists(self.dir):\n",
    "            os.makedirs(self.dir)\n",
    "        np.save(os.path.join(self.dir,name),self.logs)\n",
    "        self.logs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_map_state(map:Map):\n",
    "    dist = np.abs(map.hider_pos - map.seeker_pos).sum()\n",
    "\n",
    "    if map.get_map_layout_pos(map.hider_pos) == CHAR_MAPPING[SAFE_ZONE]:\n",
    "        state_hide = 0\n",
    "    elif map.is_end():\n",
    "        state_hide = -100000\n",
    "    elif dist == 1:\n",
    "        state_hide = -1000\n",
    "    else:\n",
    "        state_hide = (map.hider_pos**2).sum()\n",
    "\n",
    "    if  map.is_end():\n",
    "        state_seek = 100000\n",
    "    elif dist == 1:\n",
    "        state_seek = 1000\n",
    "    else:\n",
    "        state_seek = 0\n",
    "    return (state_hide+10, state_seek-10)\n",
    "\n",
    "\n",
    "def eval_map_state_hider(map:Map):\n",
    "    state_hide = 1\n",
    "    if map.get_map_layout_pos(map.hider_pos) == map.char_mapping[SAFE_ZONE]:\n",
    "        state_hide = 0\n",
    "    elif map.is_end():\n",
    "        state_hide -= REWARD\n",
    "    else:\n",
    "        state_hide += map.get_reward(map.hider_pos)\n",
    "    return state_hide\n",
    "\n",
    "def eval_map_state_seeker(map:Map):\n",
    "    state_seek=-1\n",
    "    dist = np.abs(map.hider_pos - map.seeker_pos).sum()\n",
    "    \n",
    "    if  map.is_end():\n",
    "        state_seek += REWARD\n",
    "    else:\n",
    "        state_seek = 1/dist\n",
    "    return  state_seek\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(map:Map, agent, **kwargs):\n",
    "    percepts,scent = map.get_percepts(agent)\n",
    "    perc_flat = percepts.reshape(-1)\n",
    "    one_hot_in = np.zeros((len(perc_flat), len(map.char_mapping)))\n",
    "    one_hot_in[np.arange(len(perc_flat)), perc_flat + 1] = 1 #WARNING value dependent\n",
    "    input = np.concatenate([one_hot_in.reshape(-1),scent])\n",
    "    return np.random.randint(len(ACTIONS))\n",
    "\n",
    "\n",
    "def NN_policy_simple(map:Map, agent, **kwargs):\n",
    "    pos = map.get_agent_pos(agent)\n",
    "    if agent == SEEKER:\n",
    "        network = kwargs.get(\"seek_net\")\n",
    "    else:\n",
    "        network = kwargs.get(\"hide_net\")\n",
    "\n",
    "\n",
    "    output = network.activate(map.get_percepts(agent).reshape(-1))\n",
    "    while not map.is_free(pos, agent):\n",
    "        output[np.argmax(output)] = -np.inf\n",
    "    return np.argmax(output)\n",
    "\n",
    "def NN_policy(map:Map, agent, **kwargs):\n",
    "    percepts,scent = map.get_percepts(agent)\n",
    "    perc_flat = percepts.reshape(-1)\n",
    "    one_hot_in = np.zeros((len(perc_flat), len(map.char_mapping)))\n",
    "    one_hot_in[np.arange(len(perc_flat)), perc_flat + 1] = 1 #WARNING value dependent\n",
    "    input = np.concatenate([one_hot_in.reshape(-1),scent])\n",
    "\n",
    "    pos = map.get_agent_pos(agent)\n",
    "    if agent == SEEKER:\n",
    "        network = kwargs.get(\"seek_net\")\n",
    "    else:\n",
    "        network = kwargs.get(\"hide_net\")\n",
    "        \n",
    "    output = np.copy(network.activate(input))\n",
    "    #output = np.copy(network.activate(percepts.reshape(-1)/3))\n",
    "\n",
    "    #WARNING if not working coment region\n",
    "    #region COMMENT \n",
    "    while not map.is_free(\n",
    "            pos + ACTIONS[np.argmax(output)],\n",
    "            agent\n",
    "        ): \n",
    "        output[np.argmax(output)] = -np.inf\n",
    "\n",
    "    #end region\n",
    "\n",
    "    return np.argmax(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_step(map:Map, agent, policy, **kwargs):\n",
    "\n",
    "    action = policy(map, agent, **kwargs)\n",
    "    map.do_action(agent, action)      \n",
    "\n",
    "def simulate(map:Map, map_eval, policy_hide, policy_seek, plot_func=None, num_steps = 100, **kwargs):\n",
    "    SEEK_STATE = 0\n",
    "    HIDE_STATE = 0\n",
    "    map.reset()\n",
    "    score = int(0)\n",
    "    for step in range(num_steps):\n",
    "\n",
    "        simulate_step(map, SEEKER, policy_seek, **kwargs)\n",
    "        if(not map.is_end()):\n",
    "            simulate_step(map, HIDER, policy_hide, **kwargs)\n",
    "\n",
    "        if plot_func!=None:\n",
    "            plot_func(map, kwargs.get(\"generation\"))\n",
    "        if map_eval!=None:\n",
    "            score += map_eval(map)\n",
    "            \n",
    "        map.update()\n",
    "        \n",
    "        if(map.is_end()):\n",
    "            break\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAEICAYAAACHyrIWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAM9UlEQVR4nO3df4zkdX3H8eeLOygcUMTQVj0QjmppqEnBXBSksURsipFIk/IHJrSR1FybFkVLo9ba1iaSNNZUabU/KP5qoZoGSWqIQdNUGhvLhQNMFE4bAgLHb1vwtyLy7h8zR7bH3c7c7n73u/Pm+Ug22Z35ztz79va5n+98b+Y7qSok9XHI2ANIWltGLTVj1FIzRi01Y9RSM0YtNWPUOihJvpPk5LHn0IEZ9TpLcmGSnUm+m+SR6ee/myRjz7avJDcmeePSy6rqqKq6a4A/65Iku5L8MMnH1vr+n02Meh0luQy4AvgL4HnAzwC/A5wFHLbOs2xezz9vDg8A7wE+MvYgC6+q/FiHD+AY4LvAr8/Y7ieA9wH3Ag8DfwccMb3ubGAPcBnwCPAgcPFB3vbtwEPAPwHHAtcDjwKPTT8/frr95cCPgR8A3wE+OL28gBct+Tv94/T29wDvAg6ZXvcG4D+n8zwG3A28Zo7v03uAj43977XIH67U6+dMJtH964zt/hz4OeA04EXAVuBPllz/PCYxbQV+C/hQkmMP4rbPBU4EdjDZU/vo9OsXAt8HPghQVX8EfAG4pCa73JfsZ9a/ns5yMvDLwG8CFy+5/uXA14DjgPcCH96IDzPaGfu3yrPlA7gIeGify74IPM4kplcCYbKa/+ySbc4E7p5+fvZ0281Lrn8EOGPO2z4BHL7MjKcBjy35+kbgjftsU0x+YWya3t+pS677beDG6edvAO5cct2W6W2fN+P75Eq9yo+N9riqs/8BjkuyuaqeBKiqVwAk2cNk1fwpJj/8tyxZ0MIkoKfvZ+/tp74HHDXnbR+tqh88fWWyBXg/cC6TXXGAo5Nsqqofz/j7HAccymS3e697mOwd7PXQ3k+q6nvTuY6acb9aJXe/189/AT8Ezl9mm28wWYl/oaqeM/04pqrmCWGe2+77krzLgFOAl1fVTzLZW4DJL4P9bb/vn/cjJrvue70QuH+OWTUgo14nVfU48GfA3yS5IMnRSQ5Jchpw5HSbp4B/AN6f5KcBkmxN8qtz3P9Kbns0k18Ejyd5LvCn+1z/MJPHy/v7834M/Atw+fTvciLw+8DVs2bdnySbkxzOZM9iU5LDN+AR+oVg1Ouoqt7L5Af/bUyCeRj4eyZHpL843eztwJ3ATUm+Bfwbk9V0Hgd72w8ARzBZdW8Cbtjn+iuAC5I8luSv9nP7NzF5HH8XkyPd/8zK/0vqXUx+wbyDyfGH708v00HK9OCEpCZcqaVmjFpqxqilZoxaamaQ/zJI4tE3aWBVtd+n3LpSS80YtdSMUUvNGLXUjFFLzRi11IxRS83MFXWSc5N8LcmdSd4x9FCSVm7mq7SSbAL+G/gVJieuuxl4fVXdscxtfPKJNLDVPPnkZUzONXVXVT0BfJLlz94haUTzRL0VuG/J13v4/+ehAiDJjunJ2Het1XCSDt6aPfe7qq4ErgR3v6UxzbNS3w+csOTr4/HkctKGNU/UNwMvTrItyWHAhcCnhx1L0krN3P2uqieTXAJ8lsmZHj9SVbcPPpmkFRnkxIM+ppaG5+uppWcJo5aaMWqpGaOWmjFqqZkFewMyD6ovGt/VCZa8tfC6cKWWmjFqqRmjlpoxaqkZo5aaMWqpGaOWmjFqqRmjlpoxaqkZo5aaMWqpGaOWmjFqqRmjlpoxaqkZo5aaMWqpGaOWmjFqqRmjlppZsLOJLpJhziA5xHufwZBnvPR0ouvNlVpqxqilZoxaasaopWaMWmrGqKVmjFpqZmbUSU5I8vkkdyS5Pcml6zGYpJXJrCczJHk+8PyqujXJ0cAtwK9V1R3L3GagZxws0hMZfPIJDDfvIhnwe7vfO565UlfVg1V16/TzbwO7ga1rO56ktXJQTxNNchJwOrBzP9ftAHaszViSVmrm7vfTGyZHAf8BXF5V183Y1t1vd78Bd79hA+5+AyQ5FPgUcM2soCWNa54DZQE+DvxvVb1lrjt1pcaVesKVev1X6nmi/iXgC8CXgaemF7+zqj6zzG2M2qgBo4YNGPVKGDUY9YRRb9DH1JIWh1FLzRi11IxRS80s1okH3z3QyfHevfZ3uWgHiBZtXh2YK7XUjFFLzRi11IxRS80YtdSMUUvNGLXUjFFLzRi11IxRS80YtdSMUUvNGLXUjFFLzRi11IxRS80YtdSMUUvNGLXUjFFLzRi11MxCve2OZ7z07XEWkW+7I2lVjFpqxqilZoxaasaopWaMWmrGqKVm5o46yaYktyW5fsiBJK3OwazUlwK7hxpE0tqYK+okxwOvBa4adhxJqzXvSv0B4G3AUwfaIMmOJLuS7FqLwSStzMyok5wHPFJVtyy3XVVdWVXbq2r7mk0n6aDNs1KfBbwuydeBTwKvSnL1oFNJWrGDepVWkrOBP6iq82Zs56u0BuKrtBaPr9KStCq+nnrBuFIvHldqSati1FIzRi01Y9RSM0YtNbN57AG68ii1xuJKLTVj1FIzRi01Y9RSM0YtNWPUUjNGLTVj1FIzRi01Y9RSM0YtNWPUUjNGLTVj1FIzRi01Y9RSM0YtNWPUUjNGLTVj1FIzRi0149lEB7JoZ/307Kd9uFJLzRi11IxRS80YtdSMUUvNGLXUjFFLzcwVdZLnJLk2yVeT7E5y5tCDSVqZeZ98cgVwQ1VdkOQwYMuAM0lahcx6xk+SY4AvASfXnE8PSjLI04h8dtJwfEbZcAb83u73jufZ/d4GPAp8NMltSa5KcuS+GyXZkWRXkl2rnFXSKsyzUm8HbgLOqqqdSa4AvlVVf7zMbVypF4wr9XA24kq9B9hTVTunX18LvHStBpO0tmZGXVUPAfclOWV60TnAHYNOJWnFZu5+AyQ5DbgKOAy4C7i4qh5bZnt3vxeMu9/DWe/d77miPlhGvXiMejgb8TG1pAVi1FIzRi01Y9RSM0YtNePZRBfMUEdS1YcrtdSMUUvNGLXUjFFLzRi11IxRS80YtdSMUUvNGLXUjFFLzRi11IxRS80YtdSMUUvNGLXUjFFLzRi11IxRS80YtdSMUUvNeOLBBePb2EwNcQLGJt9bV2qpGaOWmjFqqRmjlpoxaqkZo5aaMWqpmbmiTvLWJLcn+UqSTyQ5fOjBJK3MzKiTbAXeDGyvqpcAm4ALhx5M0srMu/u9GTgiyWZgC/DAcCNJWo2ZUVfV/cD7gHuBB4FvVtXn9t0uyY4ku5LsWvsxJc1rnt3vY4HzgW3AC4Ajk1y073ZVdWVVba+q7Ws/pqR5zbP7/Wrg7qp6tKp+BFwHvGLYsSSt1DxR3wuckWRLkgDnALuHHUvSSs3zmHoncC1wK/Dl6W2uHHguSSuUIV6fm2SQF6b6WmI9bYFeT50hZgWqar937DPKpGaMWmrGqKVmjFpqxqilZhbqbKJDHUWUgGGOqI/AlVpqxqilZoxaasaopWaMWmrGqKVmjFpqxqilZoxaasaopWaMWmrGqKVmjFpqxqilZoxaasaopWaMWmrGqKVmjFpqxqilZoxaamaos4l+A7hnju2Om267KBZp3kWaFRZr3o0w64kHumKQN8ibV5Jdi/Qm9Ys07yLNCos170af1d1vqRmjlpoZO+pFe/P6RZp3kWaFxZp3Q8866mNqSWtv7JVa0hozaqmZ0aJOcm6SryW5M8k7xppjliQnJPl8kjuS3J7k0rFnmkeSTUluS3L92LMsJ8lzklyb5KtJdic5c+yZlpPkrdOfg68k+USSw8eeaV+jRJ1kE/Ah4DXAqcDrk5w6xixzeBK4rKpOBc4Afm8Dz7rUpcDusYeYwxXADVX188AvsoFnTrIVeDOwvapeAmwCLhx3qmcaa6V+GXBnVd1VVU8AnwTOH2mWZVXVg1V16/TzbzP5ods67lTLS3I88FrgqrFnWU6SY4BXAh8GqKonqurxUYeabTNwRJLNwBbggZHneYaxot4K3Lfk6z1s8FAAkpwEnA7sHHmUWT4AvA14auQ5ZtkGPAp8dPpQ4aokR4491IFU1f3A+4B7gQeBb1bV58ad6pk8UDanJEcBnwLeUlXfGnueA0lyHvBIVd0y9ixz2Ay8FPjbqjod+C6wkY+vHMtkj3Ib8ALgyCQXjTvVM40V9f3ACUu+Pn562YaU5FAmQV9TVdeNPc8MZwGvS/J1Jg9rXpXk6nFHOqA9wJ6q2rvncy2TyDeqVwN3V9WjVfUj4DrgFSPP9AxjRX0z8OIk25IcxuRgw6dHmmVZScLkMd/uqvrLseeZpar+sKqOr6qTmHxf/72qNtxqAlBVDwH3JTlletE5wB0jjjTLvcAZSbZMfy7OYQMe2BvqpZfLqqonk1wCfJbJEcSPVNXtY8wyh7OA3wC+nORL08veWVWfGW+kVt4EXDP95X4XcPHI8xxQVe1Mci1wK5P/FbmNDfiUUZ8mKjXjgTKpGaOWmjFqqRmjlpoxaqkZo5aaMWqpmf8DYsAYYZSqsS8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate(\n",
    "    MAP, None,\n",
    "    random_policy, random_policy,\n",
    "    plot_map_jupiter_notebook,\n",
    "    generation = 1, num_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = Map_log(\"Test\")\n",
    "\n",
    "simulate(\n",
    "    MAP, None,\n",
    "    random_policy, random_policy,\n",
    "    log.log_map,\n",
    "    generation = 1, num_steps=50)\n",
    "\n",
    "log.save_and_reset(\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEAT\n",
    "\n",
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH_HIDER = 'config-feedforward_hider'\n",
    "CONFIG_PATH_SEEKER = 'config-feedforward_seeker'\n",
    "\n",
    "CHECKPOINT_DIR=\"checkpoints\"\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "\n",
    "#TODO fic parttools last two arguments\n",
    "FIT_SIMULATION_STEPS = 30\n",
    "EPOCHS = 10\n",
    "GENERATION = 5\n",
    "NUM_OPONENTS = 8\n",
    "\n",
    "SEEKER_FUNC=eval_map_state_seeker\n",
    "HIDER_FUNC =eval_map_state_hider\n",
    "POLICY_SEEKER =NN_policy\n",
    "POLICY_HIDER =NN_policy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_seek(genomes, config, map, hide_nets, config_hider):\n",
    "    #print(\"FITNESS SEEK\")\n",
    "    fitness = 0\n",
    "    for genome_id, genome in genomes:        \n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        for oponent_gene in hide_nets:\n",
    "            fitness += int(simulate(\n",
    "                map, SEEKER_FUNC,\n",
    "                POLICY_HIDER,POLICY_SEEKER,\n",
    "                num_steps = FIT_SIMULATION_STEPS, \n",
    "                seek_net = net,\n",
    "                hide_net = neat.nn.FeedForwardNetwork.create(oponent_gene, config_hider)\n",
    "            ))\n",
    "        genome.fitness = fitness\n",
    "\n",
    "def fitness_hide(genomes, config, map, seek_nets, config_seeker):\n",
    "    #print(\"FITNESS HIDE\")\n",
    "    fitness = 0\n",
    "    for genome_id, genome in genomes:     \n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)   \n",
    "        for oponent_gene in seek_nets:\n",
    "            fitness += int(simulate(\n",
    "            map, HIDER_FUNC,\n",
    "            POLICY_HIDER,POLICY_SEEKER,\n",
    "            num_steps = FIT_SIMULATION_STEPS, \n",
    "            seek_net = neat.nn.FeedForwardNetwork.create(oponent_gene, config_seeker),\n",
    "            hide_net = net))\n",
    "        genome.fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________ EPOCH 0 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_4\n",
      "Saving checkpoint to checkpoints\\hider_4\n",
      "______________________________ EPOCH 1 ______________________________\n",
      "______________________________ EPOCH 2 ______________________________\n",
      "______________________________ EPOCH 3 ______________________________\n",
      "______________________________ EPOCH 4 ______________________________\n",
      "______________________________ EPOCH 5 ______________________________\n",
      "______________________________ EPOCH 6 ______________________________\n",
      "______________________________ EPOCH 7 ______________________________\n",
      "______________________________ EPOCH 8 ______________________________\n",
      "______________________________ EPOCH 9 ______________________________\n"
     ]
    }
   ],
   "source": [
    "def run_evolution(config_file_hider,config_file_seeker, map: Map, epochs = 80, log_name=None, log_step= 2,verbose=0):\n",
    "    # Load configuration.\n",
    "    config_seeker = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                        neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                        config_file_seeker)\n",
    "    config_hider = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_file_hider)\n",
    "    \n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    seek_pop = neat.Population(config_seeker)\n",
    "    if verbose>1:\n",
    "        seek_pop.add_reporter(neat.StdOutReporter(True))\n",
    "        seek_pop.add_reporter(neat.StatisticsReporter())\n",
    "    seek_pop.add_reporter(neat.Checkpointer(GENERATION,filename_prefix=os.path.join(CHECKPOINT_DIR,'seeker_')))\n",
    "\n",
    "    hide_pop = neat.Population(config_hider)\n",
    "    if verbose>1:\n",
    "        hide_pop.add_reporter(neat.StdOutReporter(True))\n",
    "        hide_pop.add_reporter(neat.StatisticsReporter())\n",
    "    hide_pop.add_reporter(neat.Checkpointer(GENERATION,filename_prefix=os.path.join(CHECKPOINT_DIR,'hider_')))\n",
    "\n",
    "    winner_seek = neat.DefaultGenome(config_seeker)\n",
    "    winner_hide = neat.DefaultGenome(config_hider)\n",
    "\n",
    "    map_log = None\n",
    "    if log_name!=None:\n",
    "        map_log = Map_log(log_name)\n",
    "\n",
    "    hide_winners = [winner_hide]\n",
    "    seek_winners = [winner_seek]\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        if verbose>=0:\n",
    "            print('_'*30,'EPOCH',epoch,'_'*30)\n",
    "        # Run for up to 300 generations.\n",
    "        log = map_log!=None and ((epoch % log_step)==0)\n",
    "        \n",
    "        #Seeker evolution\n",
    "        if verbose>0:\n",
    "            print('-'*30,'SEEKER','-'*30)\n",
    "        selected_hide_winners = random.choices(hide_winners, k = NUM_OPONENTS)\n",
    "        fit_seek_fixed = functools.partial(\n",
    "            fitness_seek, map= map, hide_nets = selected_hide_winners, config_hider=config_hider\n",
    "        )\n",
    "        winner_seek = seek_pop.run(fit_seek_fixed, GENERATION)\n",
    "        seek_winners.append(winner_seek)\n",
    "        seek_pop = neat.checkpoint.Checkpointer.restore_checkpoint(\n",
    "            os.path.join(CHECKPOINT_DIR,\"seeker_\" + str( GENERATION - 1)) \n",
    "        )\n",
    "        if verbose>1:\n",
    "            seek_pop.add_reporter(neat.StdOutReporter(True))\n",
    "            seek_pop.add_reporter(neat.StatisticsReporter())\n",
    "\n",
    "        if log:\n",
    "            simulate(\n",
    "                map,None,POLICY_HIDER, POLICY_SEEKER, plot_func=map_log.log_map,\n",
    "                num_steps = FIT_SIMULATION_STEPS,\n",
    "                hide_net = neat.nn.FeedForwardNetwork.create(winner_hide,config_hider),\n",
    "                seek_net = neat.nn.FeedForwardNetwork.create(winner_seek,config_seeker)\n",
    "            )\n",
    "            map_log.save_and_reset(str(epoch*GENERATION)+\"Seeker\")\n",
    "\n",
    "        #Hider evolution\n",
    "        if verbose>0:\n",
    "            print('-'*30,'HIDER','-'*30)\n",
    "        selected_seek_winners = random.choices(seek_winners, k = NUM_OPONENTS)\n",
    "        fit_hide_fixed = functools.partial(\n",
    "            fitness_hide, map= map, seek_nets = selected_seek_winners, config_seeker=config_seeker\n",
    "        )\n",
    "        winner_hide = hide_pop.run(fit_hide_fixed, GENERATION)\n",
    "        hide_winners.append(winner_hide)\n",
    "        hide_pop = neat.checkpoint.Checkpointer.restore_checkpoint(\n",
    "            os.path.join(CHECKPOINT_DIR,'hider_'+ str( GENERATION - 1))\n",
    "        )\n",
    "        if verbose>1:\n",
    "            hide_pop.add_reporter(neat.StdOutReporter(True))\n",
    "            hide_pop.add_reporter(neat.StatisticsReporter())\n",
    "        \n",
    "        if log:\n",
    "            simulate(\n",
    "                map,None,POLICY_HIDER, POLICY_SEEKER, plot_func=map_log.log_map,\n",
    "                num_steps = FIT_SIMULATION_STEPS,\n",
    "                hide_net = neat.nn.FeedForwardNetwork.create(winner_hide,config_hider),\n",
    "                seek_net = neat.nn.FeedForwardNetwork.create(winner_seek,config_seeker)\n",
    "            )\n",
    "            map_log.save_and_reset(str(epoch*GENERATION)+\"Hider\")\n",
    "        \n",
    "    return (winner_hide, winner_seek, config_hider,config_seeker)  \n",
    "    \n",
    "\n",
    "winner_hide, winner_seek, config_hider,config_seeker = run_evolution(CONFIG_PATH_HIDER,CONFIG_PATH_SEEKER, MAP, epochs=EPOCHS, log_name=\"Neat_Test\")\n",
    "#\n",
    "    ##TODO adjust below\n",
    "    ## Display the winning genome.\n",
    "    #print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "#\n",
    "    ## Show output of the most fit genome against training data.\n",
    "    #print('\\nOutput:')\n",
    "    #winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "    ##for xi, xo in zip(xor_inputs, xor_outputs):\n",
    "    ##    output = winner_net.activate(xi)\n",
    "    ##    print(\"input {!r}, expected output {!r}, got {!r}\".format(xi, xo, output))\n",
    "#\n",
    "    #node_names = {-1: 'A', -2: 'B', 0: 'A XOR B'}\n",
    "    #visualize.draw_net(config, winner, True, node_names=node_names)\n",
    "    #visualize.draw_net(config, winner, True, node_names=node_names, prune_unused=True)\n",
    "    #visualize.plot_stats(stats, ylog=False, view=True)\n",
    "    #visualize.plot_species(stats, view=True)\n",
    "#\n",
    "    #p = neat.Checkpointer.restore_checkpoint('neat-checkpoint-4')\n",
    "    #p.run(eval_genomes, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_net(config, genome, view=False, filename=None, node_names=None, show_disabled=True, prune_unused=False,\n",
    "             node_colors=None, fmt='svg'):\n",
    "    \"\"\" Receives a genome and draws a neural network with arbitrary topology. \"\"\"\n",
    "    # Attributes for network nodes.\n",
    "    if graphviz is None:\n",
    "        warnings.warn(\"This display is not available due to a missing optional dependency (graphviz)\")\n",
    "        return\n",
    "\n",
    "    # If requested, use a copy of the genome which omits all components that won't affect the output.\n",
    "    if prune_unused:\n",
    "        genome = genome.get_pruned_copy(config.genome_config)\n",
    "\n",
    "    if node_names is None:\n",
    "        node_names = {}\n",
    "\n",
    "    assert type(node_names) is dict\n",
    "\n",
    "    if node_colors is None:\n",
    "        node_colors = {}\n",
    "\n",
    "    assert type(node_colors) is dict\n",
    "\n",
    "    node_attrs = {\n",
    "        'shape': 'circle',\n",
    "        'fontsize': '9',\n",
    "        'height': '0.2',\n",
    "        'width': '0.2'}\n",
    "\n",
    "    dot = graphviz.Digraph(format=fmt, node_attr=node_attrs)\n",
    "\n",
    "    inputs = set()\n",
    "    for k in config.genome_config.input_keys:\n",
    "        inputs.add(k)\n",
    "        name = node_names.get(k, str(k))\n",
    "        input_attrs = {'style': 'filled', 'shape': 'box', 'fillcolor': node_colors.get(k, 'lightgray')}\n",
    "        dot.node(name, _attributes=input_attrs)\n",
    "\n",
    "    outputs = set()\n",
    "    for k in config.genome_config.output_keys:\n",
    "        outputs.add(k)\n",
    "        name = node_names.get(k, str(k))\n",
    "        node_attrs = {'style': 'filled', 'fillcolor': node_colors.get(k, 'lightblue')}\n",
    "\n",
    "        dot.node(name, _attributes=node_attrs)\n",
    "\n",
    "    used_nodes = set(genome.nodes.keys())\n",
    "    for n in used_nodes:\n",
    "        if n in inputs or n in outputs:\n",
    "            continue\n",
    "\n",
    "        attrs = {'style': 'filled',\n",
    "                 'fillcolor': node_colors.get(n, 'white')}\n",
    "        dot.node(str(n), _attributes=attrs)\n",
    "\n",
    "    for cg in genome.connections.values():\n",
    "        if cg.enabled or show_disabled:\n",
    "            # if cg.input not in used_nodes or cg.output not in used_nodes:\n",
    "            #    continue\n",
    "            input, output = cg.key\n",
    "            a = node_names.get(input, str(input))\n",
    "            b = node_names.get(output, str(output))\n",
    "            style = 'solid' if cg.enabled else 'dotted'\n",
    "            color = 'green' if cg.weight > 0 else 'red'\n",
    "            width = str(0.1 + abs(cg.weight / 5.0))\n",
    "            dot.edge(a, b, _attributes={'style': style, 'color': color, 'penwidth': width})\n",
    "\n",
    "    dot.render(filename, view=view)\n",
    "\n",
    "    return dot\n",
    "\n",
    "res = draw_net(config_hider, winner_hide, True)\n",
    "res = draw_net(config_seeker, winner_seek, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = Map_log(\"Results\")\n",
    "\n",
    "simulate(\n",
    "    MAP, None,  \n",
    "    NN_policy, NN_policy,\n",
    "    plot_func=log.log_map, num_steps=100,      \n",
    "    hide_net = neat.nn.FeedForwardNetwork.create(winner_hide, config_hider),    \n",
    "    seek_net = neat.nn.FeedForwardNetwork.create(winner_seek, config_seeker),  \n",
    "    generation = GENERATION * EPOCHS,\n",
    ")\n",
    "\n",
    "log.save_and_reset( str(GENERATION * EPOCHS)+ \" result\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dfb18b20b1c5be31ebdb32c9f5f048ff20716d499c9b4ee56ead56f42de095d"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
