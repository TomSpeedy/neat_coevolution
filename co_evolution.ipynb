{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import functools\n",
    "import time\n",
    "import os\n",
    "import neat\n",
    "import warnings\n",
    "import graphviz\n",
    "import visualize\n",
    "import random\n",
    "import glob\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "WALL      = \"x\"\n",
    "FREE_SPACE= \".\"\n",
    "SAFE_ZONE = \"H\"\n",
    "HIDER     = \"h\" \n",
    "SEEKER    = \"s\"\n",
    "\n",
    "CHAR_MAPPING = {\n",
    "    WALL      : -1,\n",
    "    FREE_SPACE:  0,\n",
    "    SAFE_ZONE :  1,\n",
    "    HIDER     :  2, \n",
    "    SEEKER    :  3\n",
    "}\n",
    "\n",
    "COLOR_MAPPING = [\"black\", \"white\", \"blue\", \"green\", \"red\"]\n",
    "\n",
    "MAP_SIMPLE_NAME = \"map.txt\"\n",
    "\n",
    "ACTIONS = np.array([[-1,0], [1, 0], [0,-1], [0, 1]])\n",
    "VISION = 1\n",
    "SCENT = 5\n",
    "\n",
    "STATE_SEEK = 0\n",
    "\n",
    "REWARD =100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Map:\n",
    "        \n",
    "    def __init__(self,mapname, char_mapping):\n",
    "        #read map\n",
    "        with open(mapname, 'r') as map_file:\n",
    "            lines = map_file.readlines()\n",
    "            # width = int(lines[0])\n",
    "            # height = int(lines[1])\n",
    "            map_numbers = [[char_mapping[chr] for chr in row[:-1]] for row in lines[2:]]\n",
    "        self.char_mapping =char_mapping\n",
    "        self.map = np.array(map_numbers, dtype = np.int32)\n",
    "        self.start_hider_pos = np.asarray(np.where(self.map == char_mapping[HIDER])).reshape(2)\n",
    "        self.start_seeker_pos = np.asarray(np.where(self.map == char_mapping[SEEKER])).reshape(2)\n",
    "        \n",
    "        #action array for indexin\n",
    "        self.action_indexer = tuple(ACTIONS.T.tolist())\n",
    "        \n",
    "        #initialize map and backup map\n",
    "        self.map_layout = np.array(map_numbers, dtype = np.int32)\n",
    "        self.map_layout[self.start_hider_pos[0] ,self.start_hider_pos[1] ] = char_mapping[FREE_SPACE]\n",
    "        self.map_layout[self.start_seeker_pos[0],self.start_seeker_pos[1]] = char_mapping[FREE_SPACE]\n",
    "        \n",
    "        #initialize rewards\n",
    "        self.hider_reward = np.zeros_like(self.map_layout)-1\n",
    "        queue = np.where(self.map_layout==char_mapping[SAFE_ZONE])\n",
    "        self.hider_reward[queue]=0\n",
    "        queue = [(x,y)for x,y in zip(*queue)]\n",
    "        while len(queue)>0:\n",
    "            new_queue=[]\n",
    "            for x,y in queue:\n",
    "                for a_x,a_y in ACTIONS:\n",
    "                    if (self.get_map_layout_pos([x+a_x,y+a_y])!=char_mapping[WALL] and\n",
    "                        self.hider_reward[x+a_x,y+a_y]<0):\n",
    "                            self.hider_reward[x+a_x,y+a_y]=self.hider_reward[x,y]+1\n",
    "                            new_queue.append((x+a_x,y+a_y))\n",
    "            queue=new_queue\n",
    "        self.reset()\n",
    "    \n",
    "    def reset(self):\n",
    "        self.hider_pos  =self.start_hider_pos\n",
    "        self.seeker_pos =self.start_seeker_pos\n",
    "        self.map = np.copy(self.map_layout)\n",
    "        self.set_map_pos(self.hider_pos,  self.char_mapping[HIDER] )\n",
    "        self.set_map_pos(self.seeker_pos, self.char_mapping[SEEKER])\n",
    "\n",
    "        self.hider_reward_penalty = np.zeros_like(self.hider_reward)\n",
    "        self.scent = np.zeros_like(self.map)\n",
    "\n",
    "    def update(self):\n",
    "        pos =self.hider_pos\n",
    "        self.hider_reward_penalty[pos[0], pos[1]]+=1\n",
    "        self.scent[pos[0],pos[1]]=SCENT\n",
    "        self.scent-=1\n",
    "        self.scent = np.clip(self.scent, 0, SCENT)\n",
    "    \n",
    "    def get_map_layout_pos(self,pos):\n",
    "        return self.map_layout[pos[0], pos[1]]\n",
    "    \n",
    "    def set_map_pos(self,pos, value):\n",
    "        self.map[pos[0], pos[1]] = value\n",
    "    \n",
    "    def get_agent_pos(self, agent):\n",
    "        return self.hider_pos if agent ==HIDER else self.seeker_pos\n",
    "    \n",
    "    def set_agent_pos(self, agent, pos):\n",
    "        if agent ==HIDER:\n",
    "            self.hider_pos  =pos\n",
    "        else:\n",
    "            self.seeker_pos =pos\n",
    "    \n",
    "    def get_action_indicies(self, pos):\n",
    "        return (\n",
    "            self.action_indexer[0]+pos[0],\n",
    "            self.action_indexer[1]+pos[1],\n",
    "        )\n",
    "    \n",
    "    def get_percepts(self, agent, vision = 1):\n",
    "        pos =self.get_agent_pos(agent)\n",
    "        if agent==HIDER:\n",
    "            return (self.map[self.get_action_indicies(pos)],[])\n",
    "        else:\n",
    "            percepts = self.map[\n",
    "                pos[0] - vision : pos[0] + vision + 1,\n",
    "                pos[1] - vision : pos[1] + vision + 1\n",
    "            ]\n",
    "            scent= np.append(self.scent[self.get_action_indicies(pos)],self.map[pos[0], pos[1]])\n",
    "            return (percepts,scent) \n",
    "\n",
    "    def is_free(self, pos, agent):\n",
    "        map_pos =self.get_map_layout_pos(pos)\n",
    "        if (agent == HIDER):\n",
    "            return (\n",
    "                map_pos in [self.char_mapping[FREE_SPACE], self.char_mapping[SAFE_ZONE]] and\n",
    "                not np.all(pos == self.seeker_pos)\n",
    "            )\n",
    "        else:\n",
    "            return map_pos in [self.char_mapping[FREE_SPACE]]\n",
    "            \n",
    "    def move_agent(self, agent, new_pos):\n",
    "        pos = self.get_agent_pos(agent)\n",
    "        self.set_map_pos(pos,self.get_map_layout_pos(pos))\n",
    "        self.set_map_pos(new_pos,self.char_mapping[agent])\n",
    "        self.set_agent_pos( agent, new_pos)\n",
    "\n",
    "    def do_action(self, agent, action):\n",
    "        pos = self.get_agent_pos(agent)\n",
    "        new_pos = pos + ACTIONS[action]\n",
    "        if self.is_free(new_pos, agent):\n",
    "            self.move_agent(agent, new_pos)\n",
    "    \n",
    "    def is_end(self):\n",
    "        return np.all(self.hider_pos == self.seeker_pos)\n",
    "\n",
    "    def get_reward(self,pos):\n",
    "         return max(self.hider_reward[pos[0], pos[1]] - self.hider_reward_penalty[pos[0], pos[1]],0)\n",
    "\n",
    "        \n",
    "MAP = Map(MAP_SIMPLE_NAME,CHAR_MAPPING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_map_jupiter_notebook(map:Map,gen):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure()\n",
    "    plt.title(f\"Generation {gen}\")\n",
    "    plt.imshow(map.map, cmap = matplotlib.colors.ListedColormap(COLOR_MAPPING))\n",
    "    plt.show()\n",
    "    \n",
    "class Map_plot:\n",
    "    def __init__(self, map:Map):\n",
    "        plt.ion()\n",
    "        self.fig, self.ax = plt.subplots()\n",
    "        self.img = self.ax.imshow(map.map , cmap = matplotlib.colors.ListedColormap(COLOR_MAPPING))\n",
    "        \n",
    "    def plot_map(self,map:Map, gen):\n",
    "        self.ax.set_title(f\"Generation {gen}\")\n",
    "        self.img.set_array(map.map)\n",
    "        plt.draw()\n",
    "        self.img.canvas.flush_events()\n",
    "\n",
    "class Map_log:\n",
    "    def __init__(self, log_name):\n",
    "        self.dir = os.path.join(\"logs\",log_name)\n",
    "\n",
    "        self.logs = []\n",
    "        files = glob.glob(os.path.join(self.dir,\"*.npy\"), recursive=True)\n",
    "        for f in files:\n",
    "            try:\n",
    "                os.remove(f)\n",
    "            except OSError as e:\n",
    "                print(\"Error: %s : %s\" % (f, e.strerror))\n",
    "        \n",
    "    def log_map(self,map:Map,gen):\n",
    "\n",
    "        self.logs.append([map.hider_pos,map.seeker_pos])\n",
    "        \n",
    "    def save_and_reset(self, name):\n",
    "        if not os.path.exists(self.dir):\n",
    "            os.makedirs(self.dir)\n",
    "        np.save(os.path.join(self.dir,name),self.logs)\n",
    "        self.logs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_map_state(map:Map):\n",
    "    dist = np.abs(map.hider_pos - map.seeker_pos).sum()\n",
    "\n",
    "    if map.get_map_layout_pos(map.hider_pos) == CHAR_MAPPING[SAFE_ZONE]:\n",
    "        state_hide = 0\n",
    "    elif map.is_end():\n",
    "        state_hide = -100000\n",
    "    elif dist == 1:\n",
    "        state_hide = -1000\n",
    "    else:\n",
    "        state_hide = (map.hider_pos**2).sum()\n",
    "\n",
    "    if  map.is_end():\n",
    "        state_seek = 100000\n",
    "    elif dist == 1:\n",
    "        state_seek = 1000\n",
    "    else:\n",
    "        state_seek = 0\n",
    "    return (state_hide+10, state_seek-10)\n",
    "\n",
    "\n",
    "def eval_map_state_hider(map:Map):\n",
    "    state_hide = 1\n",
    "    if map.get_map_layout_pos(map.hider_pos) == map.char_mapping[SAFE_ZONE]:\n",
    "        state_hide = 0\n",
    "    elif map.is_end():\n",
    "        state_hide -= REWARD\n",
    "    else:\n",
    "        state_hide += map.get_reward(map.hider_pos)\n",
    "    return state_hide\n",
    "\n",
    "def eval_map_state_seeker(map:Map):\n",
    "    state_seek=-1\n",
    "    dist = np.abs(map.hider_pos - map.seeker_pos).sum()\n",
    "    \n",
    "    if  map.is_end():\n",
    "        state_seek += REWARD\n",
    "    else:\n",
    "        state_seek += 1/dist\n",
    "    return  state_seek\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_policy(map:Map, agent, **kwargs):\n",
    "    percepts,scent = map.get_percepts(agent)\n",
    "    perc_flat = percepts.reshape(-1)\n",
    "    one_hot_in = np.zeros((len(perc_flat), len(map.char_mapping)))\n",
    "    one_hot_in[np.arange(len(perc_flat)), perc_flat + 1] = 1 #WARNING value dependent\n",
    "    input = np.concatenate([one_hot_in.reshape(-1),scent])\n",
    "    return np.random.randint(len(ACTIONS)), 0\n",
    "\n",
    "\n",
    "def NN_policy(map:Map, agent, **kwargs):\n",
    "    percepts,scent = map.get_percepts(agent)\n",
    "    perc_flat = percepts.reshape(-1)\n",
    "    one_hot_in = np.zeros((len(perc_flat), len(map.char_mapping)))\n",
    "    one_hot_in[np.arange(len(perc_flat)), perc_flat + 1] = 1 #WARNING value dependent\n",
    "    \n",
    "    #input = np.concatenate([one_hot_in.reshape(-1),scent])\n",
    "    if agent == SEEKER:\n",
    "        hider_pos = map.get_agent_pos(HIDER)\n",
    "        seeker_pos = map.get_agent_pos(SEEKER)\n",
    "        hider_seek_quadrant = np.clip(hider_pos - seeker_pos, -1, 1)\n",
    "        input = np.hstack([perc_flat, hider_seek_quadrant])\n",
    "        #perc_flat[perc_flat > 1] = 0\n",
    "    else:\n",
    "        input = perc_flat\n",
    "\n",
    "    pos = map.get_agent_pos(agent)\n",
    "    if agent == SEEKER:\n",
    "        network = kwargs.get(\"seek_net\")\n",
    "    else:\n",
    "        network = kwargs.get(\"hide_net\")\n",
    "        \n",
    "    output = np.copy(network.activate(np.append(input, kwargs.get(\"state\"))))\n",
    "    state = output[-1]\n",
    "    output = output[:-1]\n",
    "    #output = np.copy(network.activate(percepts.reshape(-1)/3))\n",
    "\n",
    "    #WARNING if not working coment region\n",
    "    #region COMMENT \n",
    "    \n",
    "    #while not map.is_free(\n",
    "    #        pos + ACTIONS[np.argmax(output)],\n",
    "    #        agent\n",
    "    #    ): \n",
    "    #    output[np.argmax(output)] = -np.inf\n",
    "\n",
    "    #end region\n",
    "\n",
    "    return np.argmax(output), state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_step(map:Map, agent, policy, state, **kwargs):\n",
    "\n",
    "    action, new_state = policy(map, agent, state = state, **kwargs)\n",
    "    map.do_action(agent, action)\n",
    "    return new_state     \n",
    "\n",
    "def simulate(map:Map, map_eval, policy_hide, policy_seek, plot_func=None, num_steps = 100, **kwargs):\n",
    "    seek_state = 0\n",
    "    hide_state = 0\n",
    "    map.reset()\n",
    "    score = int(0)\n",
    "    for step in range(num_steps):\n",
    "\n",
    "        seek_state = simulate_step(map, SEEKER, policy_seek, seek_state, **kwargs)\n",
    "        if(not map.is_end()):\n",
    "            hide_state = simulate_step(map, HIDER, policy_hide, hide_state, **kwargs)\n",
    "\n",
    "        if plot_func!=None:\n",
    "            plot_func(map, kwargs.get(\"generation\"))\n",
    "        if map_eval!=None:\n",
    "            score += map_eval(map)\n",
    "            \n",
    "        map.update()\n",
    "        \n",
    "        if(map.is_end()):\n",
    "            break\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate(\n",
    "    MAP, None,\n",
    "    random_policy, random_policy,\n",
    "    plot_map_jupiter_notebook,\n",
    "    generation = 1, num_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = Map_log(\"Test\")\n",
    "\n",
    "simulate(\n",
    "    MAP, None,\n",
    "    random_policy, random_policy,\n",
    "    log.log_map,\n",
    "    generation = 1, num_steps=50)\n",
    "\n",
    "log.save_and_reset(\"random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEAT\n",
    "\n",
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH_HIDER = 'config-feedforward_hider'\n",
    "CONFIG_PATH_SEEKER = 'config-feedforward_seeker'\n",
    "\n",
    "CHECKPOINT_DIR=\"checkpoints\"\n",
    "if not os.path.exists(CHECKPOINT_DIR):\n",
    "    os.makedirs(CHECKPOINT_DIR)\n",
    "\n",
    "#TODO fic parttools last two arguments\n",
    "FIT_SIMULATION_STEPS = 30\n",
    "EPOCHS = 30\n",
    "GENERATION_SEEK = 10\n",
    "GENERATION_HIDE = 2\n",
    "NUM_OPONENTS = 8\n",
    "FITNESS_HIDE_FILE = \"./logs/fitness/best_hide.npy\"\n",
    "FITNESS_SEEK_FILE = \"./logs/fitness/best_seek.npy\"\n",
    "\n",
    "SEEKER_FUNC=eval_map_state_seeker\n",
    "HIDER_FUNC =eval_map_state_hider\n",
    "POLICY_SEEKER =NN_policy\n",
    "POLICY_HIDER =NN_policy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_seek(genomes, config, map, hide_nets, config_hider):\n",
    "    #print(\"FITNESS SEEK\")\n",
    "    fitness = 0\n",
    "    for genome_id, genome in genomes:        \n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)\n",
    "        for oponent_gene in hide_nets:\n",
    "            fitness += int(simulate(\n",
    "                map, SEEKER_FUNC,\n",
    "                POLICY_HIDER,POLICY_SEEKER,\n",
    "                num_steps = FIT_SIMULATION_STEPS, \n",
    "                seek_net = net,\n",
    "                hide_net = neat.nn.FeedForwardNetwork.create(oponent_gene, config_hider)\n",
    "            ))\n",
    "        genome.fitness = fitness\n",
    "\n",
    "def fitness_hide(genomes, config, map, seek_nets, config_seeker):\n",
    "    #print(\"FITNESS HIDE\")\n",
    "    fitness = 0\n",
    "    for genome_id, genome in genomes:     \n",
    "        net = neat.nn.FeedForwardNetwork.create(genome, config)   \n",
    "        for oponent_gene in seek_nets:\n",
    "            fitness += int(simulate(\n",
    "            map, HIDER_FUNC,\n",
    "            POLICY_HIDER,POLICY_SEEKER,\n",
    "            num_steps = FIT_SIMULATION_STEPS, \n",
    "            seek_net = neat.nn.FeedForwardNetwork.create(oponent_gene, config_seeker),\n",
    "            hide_net = net))\n",
    "        genome.fitness = fitness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "______________________________ EPOCH 0 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 1 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 2 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 3 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 4 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 5 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 6 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 7 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 8 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 9 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 10 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 11 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 12 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 13 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 14 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 15 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 16 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 17 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 18 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 19 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 20 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 21 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 22 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 23 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 24 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 25 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 26 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 27 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 28 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n",
      "______________________________ EPOCH 29 ______________________________\n",
      "Saving checkpoint to checkpoints\\seeker_9\n",
      "Saving checkpoint to checkpoints\\hider_1\n"
     ]
    }
   ],
   "source": [
    "def run_evolution(config_file_hider,config_file_seeker, map: Map, epochs = 80, log_name=None, log_step= 2,verbose=0):\n",
    "    # Load configuration.\n",
    "    config_seeker = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                        neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                        config_file_seeker)\n",
    "    config_hider = neat.Config(neat.DefaultGenome, neat.DefaultReproduction,\n",
    "                         neat.DefaultSpeciesSet, neat.DefaultStagnation,\n",
    "                         config_file_hider)\n",
    "    \n",
    "\n",
    "    # Create the population, which is the top-level object for a NEAT run.\n",
    "    seek_pop = neat.Population(config_seeker)\n",
    "    if verbose>1:\n",
    "        seek_pop.add_reporter(neat.StdOutReporter(True))\n",
    "        seek_pop.add_reporter(neat.StatisticsReporter())\n",
    "    seek_pop.add_reporter(neat.Checkpointer(GENERATION_SEEK,filename_prefix=os.path.join(CHECKPOINT_DIR,'seeker_')))\n",
    "\n",
    "    hide_pop = neat.Population(config_hider)\n",
    "    if verbose>1:\n",
    "        hide_pop.add_reporter(neat.StdOutReporter(True))\n",
    "        hide_pop.add_reporter(neat.StatisticsReporter())\n",
    "    hide_pop.add_reporter(neat.Checkpointer(GENERATION_HIDE,filename_prefix=os.path.join(CHECKPOINT_DIR,'hider_')))\n",
    "\n",
    "    winner_seek = neat.DefaultGenome(config_seeker)\n",
    "    winner_hide = neat.DefaultGenome(config_hider)\n",
    "\n",
    "    map_log = None\n",
    "    if log_name!=None:\n",
    "        map_log = Map_log(log_name)\n",
    "\n",
    "    hide_winners = [winner_hide]\n",
    "    seek_winners = [winner_seek]\n",
    "\n",
    "    best_seek_fits = []\n",
    "    best_hide_fits = []\n",
    "    for epoch in range(epochs):\n",
    "        if verbose>=0:\n",
    "            print('_'*30,'EPOCH',epoch,'_'*30)\n",
    "        # Run for up to 300 generations.\n",
    "        log = map_log!=None and ((epoch % log_step)==0)\n",
    "        \n",
    "        #Seeker evolution\n",
    "        if verbose>0:\n",
    "            print('-'*30,'SEEKER','-'*30)\n",
    "        selected_hide_winners = random.choices(hide_winners, k = NUM_OPONENTS)\n",
    "        fit_seek_fixed = functools.partial(\n",
    "            fitness_seek, map= map, hide_nets = selected_hide_winners, config_hider=config_hider\n",
    "        )\n",
    "        winner_seek = seek_pop.run(fit_seek_fixed, GENERATION_SEEK)\n",
    "        seek_winners.append(winner_seek)\n",
    "        fitness_seek([[0, winner_seek]],map = map, config = config_seeker, hide_nets= selected_hide_winners, config_hider=config_hider) #assigns fitness to winner\n",
    "        best_seek_fits.append(winner_seek.fitness)\n",
    "        \n",
    "        \n",
    "        seek_pop = neat.checkpoint.Checkpointer.restore_checkpoint(\n",
    "            os.path.join(CHECKPOINT_DIR,\"seeker_\" + str( GENERATION_SEEK - 1)) \n",
    "        )\n",
    "        seek_pop.add_reporter(neat.Checkpointer(GENERATION_SEEK,filename_prefix=os.path.join(CHECKPOINT_DIR,'seeker_')))\n",
    "\n",
    "        if verbose>1:\n",
    "            seek_pop.add_reporter(neat.StdOutReporter(True))\n",
    "            seek_pop.add_reporter(neat.StatisticsReporter())\n",
    "\n",
    "        if log:\n",
    "            simulate(\n",
    "                map,None,POLICY_HIDER, POLICY_SEEKER, plot_func=map_log.log_map,\n",
    "                num_steps = FIT_SIMULATION_STEPS,\n",
    "                hide_net = neat.nn.FeedForwardNetwork.create(winner_hide,config_hider),\n",
    "                seek_net = neat.nn.FeedForwardNetwork.create(winner_seek,config_seeker)\n",
    "            )\n",
    "            map_log.save_and_reset(str(epoch*GENERATION_SEEK)+\"Seeker\")\n",
    "\n",
    "        #Hider evolution\n",
    "        if verbose>0:\n",
    "            print('-'*30,'HIDER','-'*30)\n",
    "        selected_seek_winners = random.choices(seek_winners, k = NUM_OPONENTS)\n",
    "        fit_hide_fixed = functools.partial(\n",
    "            fitness_hide, map= map, seek_nets = selected_seek_winners, config_seeker=config_seeker\n",
    "        )\n",
    "        winner_hide = hide_pop.run(fit_hide_fixed, GENERATION_HIDE)\n",
    "        hide_winners.append(winner_hide)\n",
    "        fitness_hide([[0, winner_hide]], config = config_hider, map = map, seek_nets= selected_seek_winners, config_seeker=config_seeker) #assigns fitness to winner\n",
    "        best_hide_fits.append(winner_hide.fitness)\n",
    "        hide_pop = neat.checkpoint.Checkpointer.restore_checkpoint(\n",
    "            os.path.join(CHECKPOINT_DIR,'hider_'+ str( GENERATION_HIDE - 1))\n",
    "        )\n",
    "        hide_pop.add_reporter(neat.Checkpointer(GENERATION_HIDE,filename_prefix=os.path.join(CHECKPOINT_DIR,'hider_')))\n",
    "\n",
    "        if verbose>1:\n",
    "            hide_pop.add_reporter(neat.StdOutReporter(True))\n",
    "            hide_pop.add_reporter(neat.StatisticsReporter())\n",
    "        \n",
    "        if log:\n",
    "            simulate(\n",
    "                map,None,POLICY_HIDER, POLICY_SEEKER, plot_func=map_log.log_map,\n",
    "                num_steps = FIT_SIMULATION_STEPS,\n",
    "                hide_net = neat.nn.FeedForwardNetwork.create(winner_hide,config_hider),\n",
    "                seek_net = neat.nn.FeedForwardNetwork.create(winner_seek,config_seeker)\n",
    "            )\n",
    "            map_log.save_and_reset(str(epoch*GENERATION_HIDE)+\"Hider\")\n",
    "    if log_step > 0:\n",
    "        np.save(FITNESS_SEEK_FILE, np.array(best_seek_fits))\n",
    "        np.save(FITNESS_HIDE_FILE, np.array(best_hide_fits))    \n",
    "    return (winner_hide, winner_seek, config_hider,config_seeker)  \n",
    "    \n",
    "\n",
    "winner_hide, winner_seek, config_hider,config_seeker = run_evolution(\n",
    "    CONFIG_PATH_HIDER,CONFIG_PATH_SEEKER,\n",
    "    MAP, epochs=EPOCHS,\n",
    "    log_step= 5,log_name=\"Neat_Test\"\n",
    "    )\n",
    "#\n",
    "    ##TODO adjust below\n",
    "    ## Display the winning genome.\n",
    "    #print('\\nBest genome:\\n{!s}'.format(winner))\n",
    "#\n",
    "    ## Show output of the most fit genome against training data.\n",
    "    #print('\\nOutput:')\n",
    "    #winner_net = neat.nn.FeedForwardNetwork.create(winner, config)\n",
    "    ##for xi, xo in zip(xor_inputs, xor_outputs):\n",
    "    ##    output = winner_net.activate(xi)\n",
    "    ##    print(\"input {!r}, expected output {!r}, got {!r}\".format(xi, xo, output))\n",
    "#\n",
    "    #node_names = {-1: 'A', -2: 'B', 0: 'A XOR B'}\n",
    "    #visualize.draw_net(config, winner, True, node_names=node_names)\n",
    "    #visualize.draw_net(config, winner, True, node_names=node_names, prune_unused=True)\n",
    "    #visualize.plot_stats(stats, ylog=False, view=True)\n",
    "    #visualize.plot_species(stats, view=True)\n",
    "#\n",
    "    #p = neat.Checkpointer.restore_checkpoint('neat-checkpoint-4')\n",
    "    #p.run(eval_genomes, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_net(config, genome, view=False, filename=None, node_names=None, show_disabled=True, prune_unused=False,\n",
    "             node_colors=None, fmt='svg'):\n",
    "    \"\"\" Receives a genome and draws a neural network with arbitrary topology. \"\"\"\n",
    "    # Attributes for network nodes.\n",
    "    if graphviz is None:\n",
    "        warnings.warn(\"This display is not available due to a missing optional dependency (graphviz)\")\n",
    "        return\n",
    "\n",
    "    # If requested, use a copy of the genome which omits all components that won't affect the output.\n",
    "    if prune_unused:\n",
    "        genome = genome.get_pruned_copy(config.genome_config)\n",
    "\n",
    "    if node_names is None:\n",
    "        node_names = {}\n",
    "\n",
    "    assert type(node_names) is dict\n",
    "\n",
    "    if node_colors is None:\n",
    "        node_colors = {}\n",
    "\n",
    "    assert type(node_colors) is dict\n",
    "\n",
    "    node_attrs = {\n",
    "        'shape': 'circle',\n",
    "        'fontsize': '9',\n",
    "        'height': '0.2',\n",
    "        'width': '0.2'}\n",
    "\n",
    "    dot = graphviz.Digraph(format=fmt, node_attr=node_attrs)\n",
    "\n",
    "    inputs = set()\n",
    "    for k in config.genome_config.input_keys:\n",
    "        inputs.add(k)\n",
    "        name = node_names.get(k, str(k))\n",
    "        input_attrs = {'style': 'filled', 'shape': 'box', 'fillcolor': node_colors.get(k, 'lightgray')}\n",
    "        dot.node(name, _attributes=input_attrs)\n",
    "\n",
    "    outputs = set()\n",
    "    for k in config.genome_config.output_keys:\n",
    "        outputs.add(k)\n",
    "        name = node_names.get(k, str(k))\n",
    "        node_attrs = {'style': 'filled', 'fillcolor': node_colors.get(k, 'lightblue')}\n",
    "\n",
    "        dot.node(name, _attributes=node_attrs)\n",
    "\n",
    "    used_nodes = set(genome.nodes.keys())\n",
    "    for n in used_nodes:\n",
    "        if n in inputs or n in outputs:\n",
    "            continue\n",
    "\n",
    "        attrs = {'style': 'filled',\n",
    "                 'fillcolor': node_colors.get(n, 'white')}\n",
    "        dot.node(str(n), _attributes=attrs)\n",
    "\n",
    "    for cg in genome.connections.values():\n",
    "        if cg.enabled or show_disabled:\n",
    "            # if cg.input not in used_nodes or cg.output not in used_nodes:\n",
    "            #    continue\n",
    "            input, output = cg.key\n",
    "            a = node_names.get(input, str(input))\n",
    "            b = node_names.get(output, str(output))\n",
    "            style = 'solid' if cg.enabled else 'dotted'\n",
    "            color = 'green' if cg.weight > 0 else 'red'\n",
    "            width = str(0.1 + abs(cg.weight / 5.0))\n",
    "            dot.edge(a, b, _attributes={'style': style, 'color': color, 'penwidth': width})\n",
    "\n",
    "    dot.render(filename, view=view)\n",
    "\n",
    "    return dot\n",
    "\n",
    "res = draw_net(config_hider, winner_hide, True)\n",
    "res = draw_net(config_seeker, winner_seek, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = Map_log(\"Results\")\n",
    "\n",
    "simulate(\n",
    "    MAP, None,  \n",
    "    NN_policy, NN_policy,\n",
    "    plot_func=log.log_map, num_steps=100,      \n",
    "    hide_net = neat.nn.FeedForwardNetwork.create(winner_hide, config_hider),    \n",
    "    seek_net = neat.nn.FeedForwardNetwork.create(winner_seek, config_seeker),  \n",
    "    generation = GENERATION_SEEK * EPOCHS,\n",
    ")\n",
    "\n",
    "log.save_and_reset( str(GENERATION_SEEK * EPOCHS)+ \" result\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "886514321548a8e4bf1926f52a00fecc624bae8348bdf6e4fbd744143dc9ef89"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
